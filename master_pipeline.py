import os
import shutil
import subprocess
import sys
import json
import re
import cv2
import numpy as np

# ================= C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N =================
INPUT_DIR = "inputs"
GT_DIR = "ground_truth"
FINAL_OUTPUT_DIR = "outputs"      
OCR_SAVE_DIR = "ocr_results"      # Folder l∆∞u k·∫øt qu·∫£ OCR
TEMP_DIR = "temp"                 # Folder t·∫°m ch·ª©a ·∫£nh ƒë√£ qua x·ª≠ l√Ω
EVAL_REPORT_FILE = "final_evaluation_report.json"

# --- C·∫§U H√åNH DEEPSEEK (S·ª¨A CHO ƒê√öNG M√ÅY B·∫†N) ---
DEEPSEEK_REPO_DIR = "DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm" 
PATH_TO_OCR_SCRIPT = os.path.join(DEEPSEEK_REPO_DIR, "run_dpsk_ocr_eval_batch.py")
PATH_TO_CONFIG_FILE = os.path.join(DEEPSEEK_REPO_DIR, "config.py")

PATH_TO_LLM_SCRIPT = "deepseek_llm_7b.py"
PATH_TO_EVAL_SCRIPT = "parse_level_evaluate.py"

# ================= C√ÅC H√ÄM TI·ªÜN √çCH HI·ªÇN TH·ªä =================

def print_styled_table(title, headers, rows, col_widths):
    """H√†m in b·∫£ng ƒë·∫πp v·ªõi khung Unicode (Copy t·ª´ evaluate script)"""
    TL, TM, TR = '‚îå', '‚î¨', '‚îê'; BL, BM, BR = '‚îî', '‚î¥', '‚îò'
    VL, VR = '‚îÇ', '‚îÇ'; HL, VM = '‚îÄ', '‚îº'; ML, MR = '‚îú', '‚î§'

    fmt_parts = [f" {{{i}:{'<' if i==0 else '>'}{w}}} " for i, w in enumerate(col_widths)]
    row_fmt = VL + VL.join(fmt_parts) + VR
    
    def get_sep(left, mid, right, cross):
        segs = [mid * (w + 2) for w in col_widths]
        return left + cross.join(segs) + right

    print("\n" + " " + title.upper())
    print(get_sep(TL, HL, TR, TM))
    print(row_fmt.format(*headers))
    print(get_sep(ML, HL, MR, VM))
    for row in rows:
        print(row_fmt.format(*row))
    print(get_sep(BL, HL, BR, BM))

# ================= C√ÅC H√ÄM PIPELINE =================

def setup_dirs():
    # D·ªçn d·∫πp folder t·∫°m
    if os.path.exists(TEMP_DIR):
        shutil.rmtree(TEMP_DIR, ignore_errors=True)
        
    os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)
    os.makedirs(OCR_SAVE_DIR, exist_ok=True)
    
    if not os.path.exists(GT_DIR):
        os.makedirs(GT_DIR)

def update_deepseek_config(config_path, input_path, output_path):
    print(f"Updating config file...")
    abs_input = os.path.abspath(input_path)
    abs_output = os.path.abspath(output_path)
    
    # [QUAN TR·ªåNG] Th√™m d·∫•u / v√†o cu·ªëi ƒë∆∞·ªùng d·∫´n output ƒë·ªÉ tr√°nh l·ªói d√≠nh t√™n file
    if not abs_output.endswith(os.sep):
        abs_output += os.sep

    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Regex thay th·∫ø ƒë∆∞·ªùng d·∫´n
        content = re.sub(r"INPUT_PATH\s*=\s*['\"].*?['\"]", f"INPUT_PATH = '{abs_input}'", content)
        content = re.sub(r"OUTPUT_PATH\s*=\s*['\"].*?['\"]", f"OUTPUT_PATH = '{abs_output}'", content)
        # B·∫Øt bu·ªôc b·∫≠t ch·∫ø ƒë·ªô t·ª± c·∫Øt ·∫£nh (CROP_MODE) cho ·∫£nh d√†i
        content = re.sub(r"CROP_MODE\s*=\s*(False|True)", "CROP_MODE = True", content)

        with open(config_path, 'w', encoding='utf-8') as f:
            f.write(content) 
        print(" Config updated successfully!")
    except Exception as e:
        print(f"Error updating config: {e}")
        sys.exit(1)

def run_deepseek_ocr():
    print("\n>>> STEP 1: Running DeepSeek-OCR...")
    
    # Update config ƒë·ªÉ tr·ªè v√†o folder ·∫£nh ƒë·∫ßu v√†o
    update_deepseek_config(PATH_TO_CONFIG_FILE, INPUT_DIR, OCR_SAVE_DIR)
    
    working_dir = os.path.dirname(PATH_TO_OCR_SCRIPT)
    command = [sys.executable, PATH_TO_OCR_SCRIPT]
    
    # Ch·∫°y OCR v√† ·∫©n b·ªõt output r√°c n·∫øu mu·ªën, ·ªü ƒë√¢y ƒë·ªÉ hi·ªán ƒë·ªÉ debug
    result = subprocess.run(command, cwd=working_dir)
    if result.returncode != 0:
        print(" ERROR: DeepSeek-OCR failed!")
        sys.exit(1)

def run_deepseek_llm():
    print("\n>>> STEP 2: Running DeepSeek-LLM Extraction...")
    
    # X√≥a file r√°c _det.md sinh ra t·ª´ b∆∞·ªõc OCR
    for f in os.listdir(OCR_SAVE_DIR):
        if "_det.md" in f:
            try: os.remove(os.path.join(OCR_SAVE_DIR, f))
            except: pass

    if not os.listdir(OCR_SAVE_DIR):
        print("No markdown files found. Skipping LLM...")
        return

    command = [
        sys.executable, PATH_TO_LLM_SCRIPT,
        "--input_dir", OCR_SAVE_DIR, 
        "--output_dir", FINAL_OUTPUT_DIR
    ]
    subprocess.run(command, check=True)

def evaluate():
    print("\n>>> STEP 3: Evaluating Results...")
    
    gt_files = [f for f in os.listdir(GT_DIR) if f.endswith('.json')]
    if not gt_files:
        print(f"Skipping evaluation (No GT files in '{GT_DIR}').")
        return

    # Ch·∫°y script ƒë√°nh gi√° v√† l∆∞u k·∫øt qu·∫£ v√†o JSON, kh√¥ng in ra m√†n h√¨nh console c·ªßa subprocess
    command = [
        sys.executable, PATH_TO_EVAL_SCRIPT,
        "--gt_dir", GT_DIR,
        "--pred_dir", FINAL_OUTPUT_DIR,
        "--out", EVAL_REPORT_FILE
    ]
    
    # capture_output=True ƒë·ªÉ script ƒë√°nh gi√° kh√¥ng in b·∫£ng 2 l·∫ßn (1 l·∫ßn trong subprocess, 1 l·∫ßn ·ªü ƒë√¢y)
    result = subprocess.run(command, capture_output=True, text=True)
    
    if result.returncode == 0:
        print(f"Evaluation Calculation Complete! Reading report...")
        
        if not os.path.exists(EVAL_REPORT_FILE):
            print("Error: Report file not found.")
            return

        try:
            with open(EVAL_REPORT_FILE, 'r', encoding='utf-8') as f:
                report = json.load(f)
                
            summ = report.get('summary', {})
            total = summ.get('total_images', 0)
            
            print("\n" * 2)
            print(f"üìä  B√ÅO C√ÅO ƒê√ÅNH GI√Å T·ªîNG H·ª¢P (Images: {total})")
            print("=" * 135)
            
            # C·∫•u h√¨nh b·∫£ng hi·ªÉn th·ªã
            headers = ["FIELD", "T_PRE", "T_REC", "T_F1", "T_ACC", "C_PRE", "C_REC", "C_F1", "C_ACC", "EDIT", "WER", "CER"]
            widths =  [18,      6,       6,       6,      6,       6,       6,       6,       6,       6,      6,     6]

            # 1. OVERALL SYSTEM
            ov = summ.get("overall", {})
            rows_ov = [[
                "OVERALL",
                f"{ov.get('precision',0):.1%}", f"{ov.get('recall',0):.1%}", f"{ov.get('f1_score',0):.1%}", f"{ov.get('accuracy',0):.1%}",
                f"{ov.get('char_precision',0):.1%}", f"{ov.get('char_recall',0):.1%}", f"{ov.get('char_f1',0):.1%}", f"{ov.get('char_accuracy',0):.1%}",
                f"{ov.get('avg_edit_distance',0):.2f}", f"{ov.get('avg_wer',0):.2f}", f"{ov.get('avg_cer',0):.2f}"
            ]]
            print_styled_table("üî∑ T·ªîNG QUAN (OVERALL SYSTEM)", headers, rows_ov, widths)

            # 2. GENERAL FIELDS
            rows_gen = []
            for k, v in summ.get("fields", {}).items():
                rows_gen.append([
                    k,
                    f"{v['precision']:.1%}", f"{v['recall']:.1%}", f"{v['f1_score']:.1%}", f"{v['accuracy']:.1%}",
                    f"{v['char_precision']:.1%}", f"{v['char_recall']:.1%}", f"{v['char_f1']:.1%}", f"{v['char_accuracy']:.1%}",
                    f"{v['edit_distance']:.2f}", f"{v['wer']:.2f}", f"{v['cer']:.2f}"
                ])
            print_styled_table("üî∑ TH√îNG TIN CHUNG (HEADER FIELDS)", headers, rows_gen, widths)

            # 3. LINE ITEMS
            rows_li = []
            li_gen = summ.get("line_item", {}).get("general", {})
            li_subs = summ.get("line_item", {}).get("sub_fields", {})
            
            # System Level (Detection only)
            rows_li.append([
                "‚ñ∫ LI (SYSTEM)",
                f"{li_gen.get('precision',0):.1%}", f"{li_gen.get('recall',0):.1%}", f"{li_gen.get('f1_score',0):.1%}", f"{li_gen.get('accuracy',0):.1%}",
                "-", "-", "-", "-", 
                "-", "-", "-"
            ])
            
            # Sub-fields
            for k, v in li_subs.items():
                rows_li.append([
                    f"  ‚îî {k}",
                    f"{v['precision']:.1%}", f"{v['recall']:.1%}", f"{v['f1_score']:.1%}", f"{v['accuracy']:.1%}",
                    f"{v['char_precision']:.1%}", f"{v['char_recall']:.1%}", f"{v['char_f1']:.1%}", f"{v['char_accuracy']:.1%}",
                    f"{v['edit_distance']:.2f}", f"{v['wer']:.2f}", f"{v['cer']:.2f}"
                ])
                
            print_styled_table("üî∑ CHI TI·∫æT S·∫¢N PH·∫®M (LINE ITEMS)", headers, rows_li, widths)
            
            print("\nüìù GHI CH√ö:")
            print("  - T_...: Token Metrics (Theo t·ª´).")
            print("  - C_...: Char Metrics (Theo k√Ω t·ª±).")
            print("  - EDIT: Edit Distance (S·ªë thao t√°c s·ª≠a ƒë·ªïi).")
            print("=" * 135 + "\n")

        except Exception as e:
            print(f"Error displaying report: {e}")
            # N·∫øu l·ªói hi·ªÉn th·ªã b·∫£ng, in raw output t·ª´ subprocess ƒë·ªÉ debug
            print("Raw output from eval script:")
            print(result.stdout)
            print(result.stderr)
    else:
        print("Evaluation Script Failed!")
        print(result.stderr)

if __name__ == "__main__":
    setup_dirs()
    run_deepseek_ocr()
    run_deepseek_llm()
    evaluate()